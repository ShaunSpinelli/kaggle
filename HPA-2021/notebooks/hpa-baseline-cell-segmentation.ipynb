{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits:\n",
    "* https://www.kaggle.com/rdizzl3/hpa-segmentation-masks-no-internet\n",
    "* https://www.kaggle.com/frlemarchand/generate-masks-from-weak-image-level-labels/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\"\n",
    "!pip install -q \"../input/hpapytorchzoozip/pytorch_zoo-master\"\n",
    "!pip install -q \"../input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install torchnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Making pretrained weights work without needing to find the default filename\n",
    "if not os.path.exists('/root/.cache/torch/hub/checkpoints/'):\n",
    "        os.makedirs('/root/.cache/torch/hub/checkpoints/')\n",
    "# !cp '../input/resnet50/resnet50.pth' '/root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth'\n",
    "!cp '../input/resnet34/resnet34.pth' '/root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(labels):\n",
    "    max_classes = 18 + 1\n",
    "\n",
    "    one_hotted_labels = np.empty((len(labels), max_classes))\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        lbls_idxs = list(map(int, label.split(\"|\")))\n",
    "        lbl = np.zeros(max_classes)\n",
    "        lbl[lbls_idxs] = 1\n",
    "        one_hotted_labels[i] = lbl\n",
    "\n",
    "    return torch.tensor(one_hotted_labels).float()\n",
    "\n",
    "\n",
    "class HPADataSet(Dataset):\n",
    "    def __init__(self, image_dir, images, labels):\n",
    "        self.image_dir = image_dir\n",
    "        self.images =  images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def build_image(self, img_id):\n",
    "        r = np.array(Image.open(f\"{self.image_dir}/{img_id}_red.png\")) # mitochondria\n",
    "        b = np.array(Image.open(f\"{self.image_dir}/{img_id}_blue.png\")) # er\n",
    "        y = np.array(Image.open(f\"{self.image_dir}/{img_id}_yellow.png\")) # nuclei\n",
    "        g = np.array(Image.open(f\"{self.image_dir}/{img_id}_green.png\")) # protein of interest\n",
    "\n",
    "        img = torch.tensor(np.stack([r,b,g])/255, dtype=torch.float)\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = self.build_image(image_id)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(cls, csv, image_dir):\n",
    "        df = pd.read_csv(csv)\n",
    "        images_id = df[\"ID\"].to_numpy()\n",
    "        one_hot_labels = get_one_hot(df[\"Label\"])\n",
    "\n",
    "        return cls(image_dir, images_id, one_hot_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_dir = \"/kaggle/input/hpa-512512\"\n",
    "train_csv_path = \"/kaggle/input/hpa-single-cell-image-classification/train.csv\"\n",
    "df = pd.read_csv(train_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# x,y = dataSet[0]\n",
    "# imm = transforms.ToPILImage()(x)\n",
    "# plt.imshow(imm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorbaord Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Github Gist: https://gist.github.com/hantoine/4e7c5bc6748861968e61e60bab89e9b0\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from subprocess import Popen\n",
    "from os import chmod\n",
    "from os.path import isfile\n",
    "import json\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def download_and_unzip(url, extract_to='.'):\n",
    "    http_response = urlopen(url)\n",
    "    zipfile = ZipFile(BytesIO(http_response.read()))\n",
    "    zipfile.extractall(path=extract_to)\n",
    "\n",
    "\n",
    "def run_cmd_async_unsafe(cmd):\n",
    "    return Popen(cmd, shell=True)\n",
    "\n",
    "\n",
    "def is_process_running(process_name):\n",
    "    running_process_names = (proc.name() for proc in psutil.process_iter())\n",
    "    return process_name in running_process_names\n",
    "\n",
    "def launch_tensorboard():\n",
    "    tb_process, ngrok_process = None, None\n",
    "    \n",
    "    # Launch TensorBoard\n",
    "    if not is_process_running('tensorboard'):\n",
    "        tb_command = 'tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006'\n",
    "        tb_process = run_cmd_async_unsafe(tb_command)\n",
    "    \n",
    "    # Install ngrok\n",
    "    if not isfile('./ngrok'):\n",
    "        ngrok_url = 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip'\n",
    "        download_and_unzip(ngrok_url)\n",
    "        chmod('./ngrok', 0o755)\n",
    "\n",
    "    # Create ngrok tunnel and print its public URL\n",
    "    if not is_process_running('ngrok'):\n",
    "        ngrok_process = run_cmd_async_unsafe('./ngrok http 6006')\n",
    "        time.sleep(1) # Waiting for ngrok to start the tunnel\n",
    "    ngrok_api_res = urlopen('http://127.0.0.1:4040/api/tunnels', timeout=10)\n",
    "    ngrok_api_res = json.load(ngrok_api_res)\n",
    "    assert len(ngrok_api_res['tunnels']) > 0, 'ngrok tunnel not found'\n",
    "    tb_public_url = ngrok_api_res['tunnels'][0]['public_url']\n",
    "    print(f'TensorBoard URL: {tb_public_url}')\n",
    "\n",
    "    return tb_process, ngrok_process\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tb_process, ngrok_process = launch_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls /kaggle/working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import torchnet.meter as meter\n",
    "\n",
    "class Metric:\n",
    "    \"\"\"Base class for metrics\"\"\"\n",
    "    def __init__(self):\n",
    "        self.running_total = 0\n",
    "        self.call_count = 0\n",
    "\n",
    "    def __call__(self, predictions, labels, ):\n",
    "        \"\"\"Calculate streaming result\"\"\"\n",
    "        self.call_count += 1\n",
    "        res = self.calculation(predictions, labels)\n",
    "        self.running_total += res\n",
    "        return self.running_total/self.call_count\n",
    "\n",
    "    def calculation(self, predictions, labels):\n",
    "        \"\"\"Calculation implementation\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset Streaming Metrics\"\"\"\n",
    "        self.running_total = 0\n",
    "        self.call_count = 0\n",
    "\n",
    "class MeanAP(Metric):\n",
    "    \"\"\"Mean Average Precision\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "#         self.mAp = meter.mAPMeter()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Mean Average Precision\"\n",
    "    \n",
    "    def calculation(self, predictions, labels, logits=True):\n",
    "        if logits:\n",
    "            predictions = torch.nn.Sigmoid()(predictions)\n",
    "        # hack to get mter to work with metric my manager\n",
    "        mAp = meter.mAPMeter()\n",
    "        mAp.add(predictions, labels)\n",
    "        return mAp.value()\n",
    "#         self.mAp.reset()\n",
    "#         return res\n",
    "        \n",
    "class MetricManager:\n",
    "    \"\"\"Mangers all metrics during training\"\"\"\n",
    "    def __init__(self, metrics, writer=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metrics (list(Metrics): list of metrics\n",
    "            writer (Summary):\n",
    "        \"\"\"\n",
    "        self.metrics = metrics\n",
    "        self.writer = writer\n",
    "\n",
    "    def update(self, preds, labels, step):\n",
    "        for m in self.metrics:\n",
    "            self._update_metric(m, preds.detach().cpu(), labels.detach().cpu(), step)\n",
    "\n",
    "    def _update_metric(self, metric, preds, labels, step):\n",
    "        result = metric(preds, labels)\n",
    "        if self.writer:\n",
    "            self.writer.add_scalar(str(metric), result, step)\n",
    "        # _logger.DEBUG(f'{str(metric): {result}}')\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Call reset method on all metrics\"\"\"\n",
    "        _ = [m.reset() for m in self.metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('./logs/train-run2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will need to use torch.nn.BCEWithLogitsLoss for multilabel loss and will need to try create mulitlabel focal loss later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "resnet18 = models.resnet18()# will prob use pretrained\n",
    "resnet18.fc = torch.nn.Linear(512,19) # need to create new custom backbone\n",
    "\n",
    "resnet18.cuda()\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Training:\n",
    "    def __init__(self, metrics, loss, optim, data, epochs, model, save_dir):\n",
    "        \"\"\"Training runner\n",
    "        Args:\n",
    "            metrics (MetricManager):\n",
    "            loss (torch.nn.modules.loss):\n",
    "            optim (torch.optim):\n",
    "            data (DataLoader):\n",
    "            epochs (int):\n",
    "            model (pytorch model):\n",
    "            save_dir (str): directory to save model\n",
    "        \"\"\"\n",
    "\n",
    "        self.metrics = metrics\n",
    "        self.loss = loss\n",
    "        self.optim = optim\n",
    "        self.data = data\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.step = 0\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        data, labels = batch\n",
    "        data = data.cuda() \n",
    "        labels = labels.cuda()\n",
    "        logits = self.model(data)\n",
    "        loss = self.loss(logits, labels)\n",
    "        self.metrics.update(logits, labels, self.step)\n",
    "#         if self.step% 20 == 0: print(loss.item())\n",
    "        if self.metrics.writer:\n",
    "            self.metrics.writer.add_scalar(\"loss\", loss.item(), self.step)\n",
    "\n",
    "        self.optim.zero_grad()  # zero gradients\n",
    "        loss.backward()  # calculate gradients\n",
    "        self.optim.step()  # updated weights\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        \"\"\"Save checkpoint with current step number\"\"\"\n",
    "        torch.save(self.model.state_dict(), f'{self.save_dir}/model-{self.step}')\n",
    "\n",
    "    def run_eval(self):\n",
    "        print(\"running evaluation.....\")\n",
    "    \n",
    "    def train_loop(self):\n",
    "        for i in range(self.epochs):\n",
    "            start = time.time()\n",
    "            print(f'Epoch {i}/{self.epochs}')\n",
    "            for batch in self.data:\n",
    "                self.train_step(batch)\n",
    "                self.step += 1\n",
    "            self.metrics.reset() \n",
    "            self.save_checkpoint()\n",
    "            self.run_eval()\n",
    "            end = time.time()\n",
    "            print(f\"epoch took {(end-start)/60} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training start\n",
    "mAp = MeanAP()\n",
    "metrics = MetricManager([mAp], writer=writer)\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "optim = torch.optim.Adam(resnet18.parameters(), lr=0.001)\n",
    "\n",
    "dataset =  HPADataSet.from_csv(train_csv_path,train_images_dir)\n",
    "dl = DataLoader(dataset, batch_size=64, shuffle=True) #not ok\n",
    "\n",
    "trainer = Training(metrics, loss,  optim, dl,  10, resnet18, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_names(image_id: str) -> list:\n",
    "    # mt is the mitchondria\n",
    "    mt = f'/kaggle/input/hpa-single-cell-image-classification/test/{image_id}_red.png'    \n",
    "    # er is the endoplasmic reticulum\n",
    "    er = f'/kaggle/input/hpa-single-cell-image-classification/test/{image_id}_yellow.png'    \n",
    "    # nu is the nuclei\n",
    "    nu = f'/kaggle/input/hpa-single-cell-image-classification/test/{image_id}_blue.png'    \n",
    "    return [[mt], [er], [nu]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpacellseg.cellsegmentator as cellsegmentator\n",
    "from hpacellseg.utils import label_cell, label_nuclei\n",
    "\n",
    "NUC_MODEL = '../input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth'\n",
    "CELL_MODEL = '../input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth'\n",
    "\n",
    "segmentator = cellsegmentator.CellSegmentator(\n",
    "    NUC_MODEL,\n",
    "    CELL_MODEL,\n",
    "    scale_factor=0.25,\n",
    "    device='cuda',\n",
    "    padding=True,\n",
    "    multi_channel_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "\n",
    "\n",
    "def encode_binary_mask(mask: np.ndarray) -> t.Text:\n",
    "  \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "\n",
    "  # check input mask --\n",
    "  if mask.dtype != np.bool:\n",
    "    raise ValueError(\n",
    "        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "        mask.dtype)\n",
    "\n",
    "  mask = np.squeeze(mask)\n",
    "  if len(mask.shape) != 2:\n",
    "    raise ValueError(\n",
    "        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "        mask.shape)\n",
    "\n",
    "  # convert input mask to expected COCO API input --\n",
    "  mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "  mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "  mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "  # RLE encode mask --\n",
    "  encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "  # compress and base64 encoding --\n",
    "  binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "  base64_str = base64.b64encode(binary_str)\n",
    "  return base64_str.decode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpath = Path('../input/hpa-single-cell-image-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(tpath/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.sample(frac=0.03)\n",
    "sub.ImageWidth.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dfs = []\n",
    "for dim in sub.ImageWidth.unique():\n",
    "    df = sub[sub['ImageWidth'] == dim].copy().reset_index(drop=True)\n",
    "    sub_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_im(image_dir, img_id):\n",
    "        r = np.array(Image.open(f\"{image_dir}/{img_id}_red.png\").resize((512, 512))) # mitochondria\n",
    "        b = np.array(Image.open(f\"{image_dir}/{img_id}_blue.png\").resize((512, 512))) # er\n",
    "        y = np.array(Image.open(f\"{image_dir}/{img_id}_yellow.png\").resize((512, 512))) # nuclei\n",
    "        g = np.array(Image.open(f\"{image_dir}/{img_id}_green.png\").resize((512, 512))) # protein of interest\n",
    "        \n",
    "        \n",
    "        stacked = np.stack([r,b,g])/255\n",
    "\n",
    "        img = torch.tensor([stacked], dtype=torch.float).cuda() # add extra batch dimension\n",
    "\n",
    "        return img\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE_DIR = \"../input/hpa-single-cell-image-classification/test/\"\n",
    "POSTIVE_THRESHOLD = 0.5\n",
    "bs = 1\n",
    "for sub in sub_dfs:\n",
    "    print(f'Starting prediction for image size: {sub.ImageWidth.loc[0]}')\n",
    "    for start in range(0, len(sub), bs):\n",
    "        if start + bs > len(sub): end = len(sub)\n",
    "        else: end = start + bs\n",
    "            \n",
    "        images = []\n",
    "        for row in range(start, end):\n",
    "            image_id = sub['ID'].loc[row]\n",
    "            img = build_image_names(image_id=image_id)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.stack(images).squeeze()\n",
    "        images = np.transpose(images).tolist()\n",
    "#         print(images)\n",
    "        \n",
    "#         image_class = get_class_im(TEST_IMAGE_DIR, image_id)\n",
    "#         logits = resnet18(image_class)\n",
    "#         confidences = torch.nn.Sigmoid()(logits).cpu().detach().numpy()\n",
    "#         pred_classes = np.argwhere(confidences > POSTIVE_THRESHOLD)\n",
    "        \n",
    "\n",
    "        nuc_segmentations = segmentator.pred_nuclei(images[2]) # input here list needs to be nuclei array only (blue)\n",
    "        cell_segmentations = segmentator.pred_cells(images) # input here needs to be list on images in RYB\n",
    "\n",
    "        predstrings = []\n",
    "        for i in tqdm(range(len(cell_segmentations))): # for each image\n",
    "            _, cell_mask = label_cell(nuc_segmentations[i], cell_segmentations[i])\n",
    "            predstring = ''\n",
    "            for j in range(np.max(cell_mask)): # for each cell\n",
    "                bmask = (cell_mask == j)\n",
    "                enc = encode_binary_mask(bmask)\n",
    "                # this is where we add our predictions\n",
    "                for i in pred_classes:\n",
    "                    pred_class = i[:1]\n",
    "                    confidence = confidences[i]\n",
    "                    print(f'confidence: {confidence}, pred_class {pred_class}')\n",
    "                    predstring += f'{pred_class} {confidence} {enc } '\n",
    "            predstrings.append(predstring)\n",
    "\n",
    "        assert len(predstrings) == len(sub.loc[start:end-1])\n",
    "        sub['PredictionString'].loc[start:end-1] = predstrings\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs = pd.concat(sub_dfs, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_subs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
