{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows to import of modules\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "nb_dir\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "triplet loss function https://pytorch.org/docs/stable/nn.html#tripletmarginloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  datatset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = Path(\"/home/shaun/personal/kaggle-data/nybg2020/train/\")\n",
    "df = pd.read_csv(TRAIN_PATH/\"train.csv\")\n",
    "df_train = df[[ \"file_name\", \"category_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts  = df[\"category_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_calsses = len(label_counts) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ordered = label_counts.keys().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32094"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_calsses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datatset.HerbTripletDataSet(df_train, TRAIN_PATH,128,label=\"category_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(ds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(TRAIN_PATH/\"logs/run-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import metrics\n",
    "from train import Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc =  metrics.Accuracy()\n",
    "f1 = metrics.F1()\n",
    "manager = metrics.MetricManager([acc, f1], writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(Training):\n",
    "    def __init(self,  metrics, loss, optim, data, epochs, model, save_dir):\n",
    "        super(self).__init__(self,  metrics, loss, optim, data, epochs, model, save_dir)\n",
    "        \n",
    "    def train_step(self, batch):\n",
    "        pos, neg, anc = batch\n",
    "        logits = model(pos.img), model(neg.img), model(anc.img) # gotta be a better way\n",
    "        triplet_loss = triplet_marginloss(*logits)\n",
    "\n",
    "        # cat logits and labels for ce loss\n",
    "        join_logits = torch.cat(logits)\n",
    "        join_lables = torch.cat((pos.label, neg.label, anc.label))\n",
    "\n",
    "        # Get calssifcation logits\n",
    "        class_logits = classifier(join_logits)\n",
    "\n",
    "        ce_loss = cross_entropy(class_logits, join_lables)\n",
    "\n",
    "        loss = triplet_loss + ce_loss\n",
    "        if self.metrics.writer:\n",
    "            self.metrics.writer.add_scalar(\"loss\", loss.item(), self.step)\n",
    "            self.metrics.writer.add_scalar(\"cros_entropy_loss\", triplet_loss.item(), self.step)\n",
    "            self.metrics.writer.add_scalar(\"loss\", ce_loss.item(), self.step)\n",
    "\n",
    "        print(f'loss: {loss}')\n",
    "\n",
    "        self.optimizer.zero_grad()  # zero gradients\n",
    "        loss.backward()  # calculate gradients\n",
    "        self.optimizer.step()  # updated weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    base = models.resnet18(pretrained=True)\n",
    "    base.fc  = nn.Linear(in_features=512, out_features=512)\n",
    "    return base.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Linear(in_features=512, out_features=32204).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "triplet_marginloss = nn.TripletMarginLoss()\n",
    "cross_entropy = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_lrs = [\n",
    "    {'params': model.layer1.parameters(), 'lr': 1e-6},\n",
    "    {'params': model.layer2.parameters(), 'lr': 1e-6},\n",
    "    {'params': model.layer3.parameters(), 'lr': 1e-5},\n",
    "    {'params': model.layer4.parameters(), 'lr': 1e-4},\n",
    "    {'params': model.fc.parameters(), 'lr': 1e-3},\n",
    "    {'params': classifier.parameters(), 'lr': 1e-3}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(layer_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=TRAIN_PATH/\"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of train failed: Traceback (most recent call last):\n",
      "  File \"/home/shaun/personal/.pytorch-env/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/shaun/personal/.pytorch-env/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 450, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/shaun/personal/.pytorch-env/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 387, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/shaun/personal/.pytorch-env/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 357, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/shaun/personal/.pytorch-env/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/home/shaun/personal/.pytorch-env/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/home/shaun/personal/.pytorch-env/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 300, in update_instances\n",
      "    for obj in (obj for obj in objects if id(obj) not in visited):\n",
      "  File \"/home/shaun/personal/.pytorch-env/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 300, in <genexpr>\n",
      "    for obj in (obj for obj in objects if id(obj) not in visited):\n",
      "  File \"/home/shaun/personal/.pytorch-env/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 296, in <genexpr>\n",
      "    and not inspect.ismodule(value) )\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 64, in ismodule\n",
      "    def ismodule(object):\n",
      "KeyboardInterrupt\n",
      "]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0478706237b429db4717a101d269a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=64422), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 11.5514554977417\n",
      "loss: 11.519807815551758\n",
      "loss: 11.51269245147705\n",
      "loss: 11.379258155822754\n",
      "loss: 11.372251510620117\n",
      "loss: 11.698086738586426\n",
      "loss: 11.748482704162598\n",
      "loss: 11.663235664367676\n",
      "loss: 12.047969818115234\n",
      "loss: 11.81884479522705\n",
      "loss: 11.641877174377441\n",
      "loss: 11.367223739624023\n",
      "loss: 11.328934669494629\n",
      "loss: 12.128104209899902\n",
      "loss: 12.123634338378906\n",
      "loss: 11.382646560668945\n",
      "loss: 11.89951229095459\n",
      "loss: 11.474444389343262\n",
      "loss: 11.532544136047363\n",
      "loss: 11.695939064025879\n",
      "loss: 11.4854154586792\n",
      "loss: 11.543900489807129\n",
      "loss: 11.357575416564941\n",
      "loss: 11.493578910827637\n",
      "loss: 11.530760765075684\n",
      "loss: 11.655909538269043\n",
      "loss: 11.53950309753418\n",
      "loss: 11.565032958984375\n",
      "loss: 11.347163200378418\n",
      "loss: 11.613289833068848\n",
      "loss: 11.855154991149902\n",
      "loss: 11.50229263305664\n",
      "loss: 11.94113826751709\n",
      "loss: 11.851414680480957\n",
      "loss: 11.27842903137207\n",
      "loss: 11.825401306152344\n",
      "loss: 11.853523254394531\n",
      "loss: 11.184727668762207\n",
      "loss: 11.420722007751465\n",
      "loss: 11.655486106872559\n",
      "loss: 12.398829460144043\n",
      "loss: 11.91860294342041\n",
      "loss: 12.03085708618164\n",
      "loss: 11.652703285217285\n",
      "loss: 11.437528610229492\n",
      "loss: 11.715492248535156\n",
      "loss: 11.446234703063965\n",
      "loss: 11.963573455810547\n",
      "loss: 11.666534423828125\n",
      "loss: 12.028267860412598\n",
      "loss: 11.31673526763916\n",
      "loss: 11.693782806396484\n",
      "loss: 12.164216041564941\n",
      "loss: 12.118462562561035\n",
      "loss: 12.327399253845215\n",
      "loss: 11.684454917907715\n",
      "loss: 11.718110084533691\n",
      "loss: 11.874579429626465\n",
      "loss: 12.012005805969238\n",
      "loss: 11.6325044631958\n",
      "loss: 11.63620662689209\n",
      "loss: 11.623248100280762\n",
      "loss: 11.602513313293457\n",
      "loss: 11.063743591308594\n",
      "loss: 11.62122631072998\n",
      "loss: 11.599438667297363\n",
      "loss: 11.7811918258667\n",
      "loss: 11.554936408996582\n",
      "loss: 11.270740509033203\n",
      "loss: 11.250044822692871\n",
      "loss: 11.563849449157715\n",
      "loss: 11.772266387939453\n",
      "loss: 11.589323043823242\n",
      "loss: 11.150834083557129\n",
      "loss: 11.66738510131836\n",
      "loss: 11.808643341064453\n",
      "loss: 11.88890552520752\n",
      "loss: 11.795668601989746\n",
      "loss: 11.945480346679688\n",
      "loss: 11.192996978759766\n",
      "loss: 11.53987979888916\n",
      "loss: 11.6192626953125\n",
      "loss: 11.468772888183594\n",
      "loss: 11.651326179504395\n",
      "loss: 11.785530090332031\n",
      "loss: 11.117402076721191\n",
      "loss: 10.904471397399902\n",
      "loss: 11.914048194885254\n",
      "loss: 11.714259147644043\n",
      "loss: 11.911406517028809\n",
      "loss: 11.542155265808105\n",
      "loss: 11.936686515808105\n",
      "loss: 12.00672435760498\n",
      "loss: 11.869712829589844\n",
      "loss: 11.305140495300293\n",
      "loss: 11.840914726257324\n",
      "loss: 11.074481964111328\n",
      "loss: 11.77413272857666\n",
      "loss: 11.560050010681152\n",
      "loss: 11.711200714111328\n",
      "loss: 11.753008842468262\n",
      "loss: 11.604077339172363\n",
      "loss: 11.519440650939941\n",
      "loss: 11.520707130432129\n",
      "loss: 11.190485954284668\n",
      "loss: 11.445856094360352\n",
      "loss: 11.497294425964355\n",
      "loss: 10.869962692260742\n",
      "loss: 10.50163745880127\n",
      "loss: 11.6753568649292\n",
      "loss: 11.63891887664795\n",
      "loss: 11.330427169799805\n",
      "loss: 11.718101501464844\n",
      "loss: 10.996735572814941\n",
      "loss: 11.617387771606445\n",
      "loss: 11.751832008361816\n",
      "loss: 11.60828685760498\n",
      "loss: 10.965424537658691\n",
      "loss: 12.046966552734375\n",
      "loss: 11.054608345031738\n",
      "loss: 11.549229621887207\n",
      "loss: 10.92906665802002\n",
      "loss: 11.839003562927246\n",
      "loss: 11.87890625\n",
      "loss: 10.866341590881348\n",
      "loss: 11.385627746582031\n",
      "loss: 11.900581359863281\n",
      "loss: 12.039301872253418\n",
      "loss: 11.709705352783203\n",
      "loss: 11.540105819702148\n",
      "loss: 11.75732421875\n",
      "loss: 11.41735553741455\n",
      "loss: 12.34481143951416\n",
      "loss: 11.694400787353516\n",
      "loss: 10.94243335723877\n",
      "loss: 11.452177047729492\n",
      "loss: 11.146452903747559\n",
      "loss: 11.572917938232422\n",
      "loss: 11.583245277404785\n",
      "loss: 11.51486873626709\n",
      "loss: 11.326249122619629\n",
      "loss: 11.468585014343262\n",
      "loss: 10.884986877441406\n",
      "loss: 12.070963859558105\n",
      "loss: 11.572509765625\n",
      "loss: 11.23500919342041\n",
      "loss: 11.746468544006348\n",
      "loss: 11.469788551330566\n",
      "loss: 11.897712707519531\n",
      "loss: 11.843204498291016\n",
      "loss: 11.842255592346191\n",
      "loss: 11.22081184387207\n",
      "loss: 11.4911527633667\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/personal/kaggle/herbarium_2020/train.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/kaggle/herbarium_2020/train.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-36ef95523fcb>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/.pytorch-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/.pytorch-env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/kaggle/herbarium_2020/datatset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mimage_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-255cf8a73675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/personal/kaggle/herbarium_2020/train.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Quitting due to user cancel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/kaggle/herbarium_2020/train.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;34m\"\"\"Save checkpoint with current step number\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{self.save_dir}/model-{self.step}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "Trainer(manager, None, optimizer, data_loader, 3, None, model_path).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
