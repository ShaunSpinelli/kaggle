{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/home/shaun/data/kaggle/iwild/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shaun/data/kaggle/iwild/sample_submission.csv\n",
      "/home/shaun/data/kaggle/iwild/train.csv\n",
      "/home/shaun/data/kaggle/iwild/animal_preds_train_res50-1.npy\n",
      "/home/shaun/data/kaggle/iwild/is_animal_train-res50.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i) for i in PATH.iterdir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == labels).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_animal = np.load(PATH/\"is_animal_train-res50.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196299, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_animal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = np.load(PATH/\"animal_preds_train_res50-1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196299, 13)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = np.concatenate((is_animal, animal), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH/\"train.csv\")\n",
    "classes = df[\"category_id\"].unique()\n",
    "classes_map = {classes[i]:i for i in range(len(classes))}\n",
    "new_labels = np.array([ classes_map[i] for i in df[\"category_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 6,\n",
       " 3: 2,\n",
       " 4: 4,\n",
       " 8: 3,\n",
       " 10: 12,\n",
       " 11: 7,\n",
       " 13: 5,\n",
       " 14: 10,\n",
       " 16: 8,\n",
       " 17: 9,\n",
       " 18: 11,\n",
       " 19: 0,\n",
       " 22: 13}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196299"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = joined\n",
    "y = new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=200\n",
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x[split:], y[split:], x[:split], y[:split])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "valid_dataset = TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=bs)\n",
    "valid_data_lodaer = DataLoader(valid_dataset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 15\n",
    "num_classes = 14\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, num_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=15, out_features=30, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=30, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(batch, train):\n",
    "    data, labels = batch #get batch\n",
    "    out = model(data.float()) # get predictions\n",
    "    loss = ce_loss(out, labels) # calcualte loss\n",
    "    acc = accuracy(out, labels)\n",
    "    if train:\n",
    "        optim.zero_grad() # zero graidents\n",
    "        loss.backward() # calcualte gradients\n",
    "        optim.step() #update parameters\n",
    "\n",
    "    return loss.item(), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, train=True):\n",
    "    loss_hist = []\n",
    "    acc_hist = []\n",
    "    for batch in dataloader:\n",
    "        loss_t, acc_t = step(batch, train=train)\n",
    "        loss_hist.append(loss_t)\n",
    "        acc_hist.append(acc_t)\n",
    "        \n",
    "    return np.mean(loss_hist), np.mean(acc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      " Train Loss: 1.615, Valid Loss:0.727\n",
      " Train acc: 0.6579999923706055, Valid acc:0.7799999713897705\n",
      "Epoch: 1\n",
      " Train Loss: 0.504, Valid Loss:0.348\n",
      " Train acc: 0.8880000114440918, Valid acc:0.9350000023841858\n",
      "Epoch: 2\n",
      " Train Loss: 0.277, Valid Loss:0.224\n",
      " Train acc: 0.9409999847412109, Valid acc:0.949999988079071\n",
      "Epoch: 3\n",
      " Train Loss: 0.213, Valid Loss:0.188\n",
      " Train acc: 0.9459999799728394, Valid acc:0.949999988079071\n",
      "Epoch: 4\n",
      " Train Loss: 0.193, Valid Loss:0.173\n",
      " Train acc: 0.9470000267028809, Valid acc:0.949999988079071\n",
      "Epoch: 5\n",
      " Train Loss: 0.186, Valid Loss:0.167\n",
      " Train acc: 0.9470000267028809, Valid acc:0.9549999833106995\n",
      "Epoch: 6\n",
      " Train Loss: 0.182, Valid Loss:0.163\n",
      " Train acc: 0.9470000267028809, Valid acc:0.949999988079071\n",
      "Epoch: 7\n",
      " Train Loss: 0.18, Valid Loss:0.161\n",
      " Train acc: 0.9470000267028809, Valid acc:0.949999988079071\n",
      "Epoch: 8\n",
      " Train Loss: 0.179, Valid Loss:0.16\n",
      " Train acc: 0.9470000267028809, Valid acc:0.949999988079071\n",
      "Epoch: 9\n",
      " Train Loss: 0.178, Valid Loss:0.159\n",
      " Train acc: 0.9480000138282776, Valid acc:0.949999988079071\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_train = np.empty(epochs)\n",
    "acc_train = np.empty(epochs)\n",
    "loss_eval = np.empty(epochs)\n",
    "acc_eval = np.empty(epochs)\n",
    "\n",
    "for ep  in range(epochs):\n",
    "    print(f'Epoch: {ep}')\n",
    "    loss_t, acc_t = train_epoch(train_data_loader)\n",
    "    loss_v, acc_v = train_epoch(valid_data_lodaer, train=False)\n",
    "    loss_train[ep], acc_train[ep], loss_eval[ep], acc_eval[ep] =  loss_t, acc_t, loss_v, acc_v\n",
    "    print(f' Train Loss: {np.round(loss_t,3)}, Valid Loss:{np.round(loss_v,3)}')\n",
    "    print(f' Train acc: {np.round(acc_t,3)}, Valid acc:{np.round(acc_v,3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
