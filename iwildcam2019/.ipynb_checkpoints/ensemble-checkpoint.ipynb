{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/home/ubuntu/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/train\n",
      "/home/ubuntu/data/test.csv\n",
      "/home/ubuntu/data/train.csv\n",
      "/home/ubuntu/data/test\n",
      "/home/ubuntu/data/models\n",
      "/home/ubuntu/data/animal_preds_train_res34.npy\n",
      "/home/ubuntu/data/test-animal-preds-res50.npy\n",
      "/home/ubuntu/data/is_animal_train-res50.npy\n",
      "/home/ubuntu/data/test-is-animal-res50.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i) for i in PATH.iterdir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == labels).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_animal = np.load(PATH/\"is_animal_train-res50.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196299, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_animal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = np.load(PATH/\"animal_preds_train_res34.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196299, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for i,pred in zip(is_animal_f,animal_preds_f):\n",
    "    if i:\n",
    "        final_preds.append(class_map_reversed[pred])\n",
    "    else:\n",
    "        final_preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = np.concatenate((is_animal, animal), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH/\"train.csv\")\n",
    "classes = df[\"category_id\"].unique()\n",
    "classes_map = {classes[i]:i for i in range(len(classes))}\n",
    "new_labels = np.array([ classes_map[i] for i in df[\"category_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{19: 0,\n",
       " 0: 1,\n",
       " 3: 2,\n",
       " 8: 3,\n",
       " 4: 4,\n",
       " 13: 5,\n",
       " 1: 6,\n",
       " 11: 7,\n",
       " 16: 8,\n",
       " 17: 9,\n",
       " 14: 10,\n",
       " 18: 11,\n",
       " 10: 12,\n",
       " 22: 13}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196299"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = joined\n",
    "y = new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idxs = np.random.permutation(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=200\n",
    "train_idxs = random_idxs[split:]\n",
    "valid_idx = random_idxs[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x[split:], y[split:], x[:split], y[:split])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "valid_dataset = TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=bs)\n",
    "valid_data_lodaer = DataLoader(valid_dataset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 15\n",
    "num_classes = 14\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, num_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=15, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(batch, train):\n",
    "    data, labels = batch #get batch\n",
    "    out = model(data.float()) # get predictions\n",
    "    loss = ce_loss(out, labels) # calcualte loss\n",
    "    acc = accuracy(out, labels)\n",
    "    if train:\n",
    "        optim.zero_grad() # zero graidents\n",
    "        loss.backward() # calcualte gradients\n",
    "        optim.step() #update parameters\n",
    "\n",
    "    return loss.item(), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, train=True):\n",
    "    loss_hist = []\n",
    "    acc_hist = []\n",
    "    for batch in dataloader:\n",
    "        loss_t, acc_t = step(batch, train=train)\n",
    "        loss_hist.append(loss_t)\n",
    "        acc_hist.append(acc_t)\n",
    "        \n",
    "    return np.mean(loss_hist), np.mean(acc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      " Train Loss: 1.348, Valid Loss:0.576\n",
      " Train acc: 0.6990000009536743, Valid acc:0.8899999856948853\n",
      "Epoch: 1\n",
      " Train Loss: 0.331, Valid Loss:0.148\n",
      " Train acc: 0.9419999718666077, Valid acc:0.9850000143051147\n",
      "Epoch: 2\n",
      " Train Loss: 0.147, Valid Loss:0.077\n",
      " Train acc: 0.9660000205039978, Valid acc:0.9850000143051147\n",
      "Epoch: 3\n",
      " Train Loss: 0.113, Valid Loss:0.063\n",
      " Train acc: 0.9679999947547913, Valid acc:0.9850000143051147\n",
      "Epoch: 4\n",
      " Train Loss: 0.104, Valid Loss:0.058\n",
      " Train acc: 0.968999981880188, Valid acc:0.9850000143051147\n",
      "Epoch: 5\n",
      " Train Loss: 0.101, Valid Loss:0.056\n",
      " Train acc: 0.968999981880188, Valid acc:0.9850000143051147\n",
      "Epoch: 6\n",
      " Train Loss: 0.1, Valid Loss:0.055\n",
      " Train acc: 0.968999981880188, Valid acc:0.9850000143051147\n",
      "Epoch: 7\n",
      " Train Loss: 0.099, Valid Loss:0.055\n",
      " Train acc: 0.968999981880188, Valid acc:0.9850000143051147\n",
      "Epoch: 8\n",
      " Train Loss: 0.099, Valid Loss:0.054\n",
      " Train acc: 0.968999981880188, Valid acc:0.9850000143051147\n",
      "Epoch: 9\n",
      " Train Loss: 0.098, Valid Loss:0.054\n",
      " Train acc: 0.968999981880188, Valid acc:0.9850000143051147\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_train = np.empty(epochs)\n",
    "acc_train = np.empty(epochs)\n",
    "loss_eval = np.empty(epochs)\n",
    "acc_eval = np.empty(epochs)\n",
    "\n",
    "for ep  in range(epochs):\n",
    "    print(f'Epoch: {ep}')\n",
    "    loss_t, acc_t = train_epoch(train_data_loader)\n",
    "    loss_v, acc_v = train_epoch(valid_data_lodaer, train=False)\n",
    "    loss_train[ep], acc_train[ep], loss_eval[ep], acc_eval[ep] =  loss_t, acc_t, loss_v, acc_v\n",
    "    print(f' Train Loss: {np.round(loss_t,3)}, Valid Loss:{np.round(loss_v,3)}')\n",
    "    print(f' Train acc: {np.round(acc_t,3)}, Valid acc:{np.round(acc_v,3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_e = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_animal_t = np.load(PATH/\"test-is-animal-res50.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_t = np.load(PATH/\"test-animal-preds-res50.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = np.concatenate((is_animal_t, animal_t), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153730, 15)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_t = torch.from_numpy(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_ds = TensorDataset(joined_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinded_dl = DataLoader(joined_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for b in joinded_dl:\n",
    "    pred =  model_e(b[0])\n",
    "    final_preds.extend(np.argmax(pred.detach().numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_preds) == len(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_map_reversed = {v:k for k,v in classes_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_final_preds = [classes_map_reversed[i] for i in final_preds ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_final_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(PATH/\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Predicted\"] =  final_final_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subm = df_test[[\"id\",\"Predicted\" ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bce932f6-2bf6-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bce932f7-2bf6-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bce932f8-2bf6-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bce932f9-2bf6-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bce932fa-2bf6-11e9-bcad-06f10d5896c4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  Predicted\n",
       "0  bce932f6-2bf6-11e9-bcad-06f10d5896c4          0\n",
       "1  bce932f7-2bf6-11e9-bcad-06f10d5896c4          0\n",
       "2  bce932f8-2bf6-11e9-bcad-06f10d5896c4          0\n",
       "3  bce932f9-2bf6-11e9-bcad-06f10d5896c4          0\n",
       "4  bce932fa-2bf6-11e9-bcad-06f10d5896c4          0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subm.to_csv(\"subm_ens3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5.76M/5.76M [00:03<00:00, 1.72MB/s]\n",
      "Successfully submitted to iWildCam 2019 - FGVC6"
     ]
    }
   ],
   "source": [
    "! kaggle competitions submit -c iwildcam-2019-fgvc6 -f subm_ens3.csv -m \"Ensemble submission 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
