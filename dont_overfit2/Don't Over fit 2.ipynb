{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "* setup proper initalisation of model weights\n",
    "* use same drop out they used in paper\n",
    "* weight the underrepresented class\n",
    "* k-fold validation\n",
    "\n",
    "## things to try\n",
    "\n",
    "* data augmentation\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  test.csv.zip  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls ~/data/kaggle/dont-overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"~/data/kaggle/dont-overfit/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train.drop(columns=['target','id']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(x)\n",
    "std = np.std(x)\n",
    "\n",
    "def normalize(X):\n",
    "    return (X-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DofDataset(Dataset):\n",
    "    def __init__(self,df, test=False):\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "            \n",
    "    @property\n",
    "    def tensor_labels(self):\n",
    "        return torch.from_numpy(self.df.target.values).long()\n",
    "    \n",
    "    @property\n",
    "    def tensor_data(self): #need to normalise data\n",
    "        if self.test:\n",
    "            return torch.from_numpy(self.df.drop(columns=['id']).values).float()\n",
    "        return torch.from_numpy(self.df.drop(columns=['target', 'id']).values).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if self.test:\n",
    "            return self.tensor_data[idx]\n",
    "        label = self.tensor_labels[idx]\n",
    "        data = self.tensor_data[idx]\n",
    "        \n",
    "        return label, data\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = np.mean(X_train)\n",
    "# std = np.std(X_train)\n",
    "\n",
    "# def standardize(x):\n",
    "#     return (x-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dod_ds = DofDataset(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(preds,labels):\n",
    "#     preds_np = np.argmax(preds.detach().numpy(), axis=1)\n",
    "#     return np.sum(preds_np == labels.detach().numpy())/len(preds_np)\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 300\n",
    "out_size = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_size, 600, bias=True),\n",
    "    nn.SELU(),\n",
    "    nn.Linear(600, 300, bias=True),\n",
    "    nn.SELU(),\n",
    "    nn.Linear(300, out_size, bias=True),\n",
    "    nn.SELU(),\n",
    "    nn.Dropout(p=0.7))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        size = m.in_features\n",
    "        nn.init.normal_(m.weight,  mean=0, std=1/math.sqrt(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "  (1): SELU()\n",
       "  (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "  (3): SELU()\n",
       "  (4): Linear(in_features=300, out_features=2, bias=True)\n",
       "  (5): SELU()\n",
       "  (6): Dropout(p=0.7)\n",
       ")"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-6\n",
    "bs = 30\n",
    "\n",
    "cross_en = nn.CrossEntropyLoss()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "dod_df = DataLoader(dod_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch, train):\n",
    "    labels, data = batch\n",
    "    data_norm = normalize(data)\n",
    "    preds = model(data_norm)\n",
    "    loss = cross_en(preds, labels)\n",
    "    acc = accuracy(preds,labels)\n",
    "    if train:\n",
    "        optim.zero_grad() # zero gradients (?? why do we do this)\n",
    "        loss.backward() # calcuate gradients\n",
    "        optim.step() # updated weights\n",
    "    return loss.item(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_t = []\n",
    "train_acc_t = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 Train Loss:  0.3605426102876663, Accuracy 0.7777777910232544\n",
      "epoch:1 Train Loss:  0.32222340669896865, Accuracy 0.859259307384491\n",
      "epoch:2 Train Loss:  0.35040323932965595, Accuracy 0.7962962985038757\n",
      "epoch:3 Train Loss:  0.3145899805757735, Accuracy 0.8370369672775269\n",
      "epoch:4 Train Loss:  0.34004322025511, Accuracy 0.800000011920929\n",
      "epoch:5 Train Loss:  0.3502122826046414, Accuracy 0.8148148059844971\n",
      "epoch:6 Train Loss:  0.3631708323955536, Accuracy 0.7999999523162842\n",
      "epoch:7 Train Loss:  0.3681585027111901, Accuracy 0.7925925850868225\n",
      "epoch:8 Train Loss:  0.3528202242321438, Accuracy 0.8037037253379822\n",
      "epoch:9 Train Loss:  0.34253713488578796, Accuracy 0.8259259462356567\n",
      "epoch:10 Train Loss:  0.40141502353880143, Accuracy 0.7777777910232544\n",
      "epoch:11 Train Loss:  0.3859183258480496, Accuracy 0.7999999523162842\n",
      "epoch:12 Train Loss:  0.32698221504688263, Accuracy 0.82962965965271\n",
      "epoch:13 Train Loss:  0.37334882881906295, Accuracy 0.8111111521720886\n",
      "epoch:14 Train Loss:  0.3809472488032447, Accuracy 0.825925886631012\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    train_loss_ep = []\n",
    "    train_acc_ep = []\n",
    "    \n",
    "    for train_batch in dod_df :\n",
    "        train_loss, train_acc = train_step(train_batch, True)\n",
    "        train_loss_ep.append(train_loss)\n",
    "        train_acc_ep.append(train_acc)\n",
    "    if i% 1 == 0:\n",
    "        print(f'epoch:{i} Train Loss:  {np.mean(train_loss_ep)}, Accuracy {np.mean(train_acc_ep)}')\n",
    "    train_loss_t.append(np.mean(train_loss_ep))\n",
    "    train_acc_t.append(np.mean(train_acc_ep))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"~/data/kaggle/dont-overfit/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = DofDataset(df_test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_ds, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 10s, sys: 41.4 s, total: 14min 51s\n",
      "Wall time: 14min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(test_dl):\n",
    "    logits = model(batch)\n",
    "    preds_np = np.argmax(logits.detach().numpy(), axis=1)\n",
    "    preds.extend(preds_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samp = pd.read_csv(\"~/data/kaggle/dont-overfit/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samp[\"target\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_samp.to_csv(\"subm-8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 144k/144k [00:08<00:00, 18.3kB/s]\n",
      "Successfully submitted to Don't Overfit! II"
     ]
    }
   ],
   "source": [
    "! kaggle competitions submit -c dont-overfit-ii -f subm-8.csv -m \"snn layer nn normalised drop 0.5, initalised with 1/2sqrt in layer, pla with train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
