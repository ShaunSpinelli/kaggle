{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "* setup proper initalisation of model weights\n",
    "* use same drop out they used in paper\n",
    "* weight the underrepresented class\n",
    "* k-fold validation\n",
    "\n",
    "## things to try\n",
    "\n",
    "* data augmentation\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred-ens1.csv  sample_submission.csv  test.csv.zip\r\n",
      "pred-ens.csv   test.csv\t\t      train.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls ~/data/kaggle/dont-overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"~/data/kaggle/dont-overfit/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train.drop(columns=['target','id']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(x)\n",
    "std = np.std(x)\n",
    "\n",
    "def normalize(X):\n",
    "    return (X-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DofDataset(Dataset):\n",
    "    def __init__(self,df, test=False):\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "            \n",
    "    @property\n",
    "    def tensor_labels(self):\n",
    "        return torch.from_numpy(self.df.target.values).long()\n",
    "    \n",
    "    @property\n",
    "    def tensor_data(self): #need to normalise data\n",
    "        if self.test:\n",
    "            return torch.from_numpy(self.df.drop(columns=['id']).values).float()\n",
    "        return torch.from_numpy(self.df.drop(columns=['target', 'id']).values).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if self.test:\n",
    "            return self.tensor_data[idx]\n",
    "        label = self.tensor_labels[idx]\n",
    "        data = self.tensor_data[idx]\n",
    "        \n",
    "        return label, data\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = np.mean(X_train)\n",
    "# std = np.std(X_train)\n",
    "\n",
    "# def standardize(x):\n",
    "#     return (x-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dod_ds = DofDataset(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(preds,labels):\n",
    "#     preds_np = np.argmax(preds.detach().numpy(), axis=1)\n",
    "#     return np.sum(preds_np == labels.detach().numpy())/len(preds_np)\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 300\n",
    "out_size = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_size, 600, bias=True),\n",
    "    nn.SELU(),\n",
    "    nn.Linear(600, 300, bias=True),\n",
    "    nn.SELU(),\n",
    "    nn.Dropout(p=0.7),\n",
    "    nn.Linear(300, out_size, bias=True))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        size = m.in_features\n",
    "        nn.init.normal_(m.weight,  mean=0, std=1/math.sqrt(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "  (1): SELU()\n",
       "  (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "  (3): SELU()\n",
       "  (4): Dropout(p=0.7)\n",
       "  (5): Linear(in_features=300, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "bs = 50\n",
    "\n",
    "cross_en = nn.CrossEntropyLoss()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dod_df = DataLoader(dod_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch, train):\n",
    "    labels, data = batch\n",
    "    data_norm = normalize(data)\n",
    "    preds = model(data_norm)\n",
    "    loss = cross_en(preds, labels)\n",
    "    acc = accuracy(preds,labels)\n",
    "    if train:\n",
    "        optim.zero_grad() # zero gradients (?? why do we do this)\n",
    "        loss.backward() # calcuate gradients\n",
    "        optim.step() # updated weights\n",
    "    return loss.item(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_t = []\n",
    "train_acc_t = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 Train Loss:  1.3482912302017211, Accuracy 0.46400004625320435\n",
      "epoch:1 Train Loss:  1.076285982131958, Accuracy 0.5200000405311584\n",
      "epoch:2 Train Loss:  1.0576185226440429, Accuracy 0.5879999995231628\n",
      "epoch:3 Train Loss:  0.9004774570465088, Accuracy 0.6000000238418579\n",
      "epoch:4 Train Loss:  1.0499745607376099, Accuracy 0.5359999537467957\n",
      "epoch:5 Train Loss:  0.8441011428833007, Accuracy 0.6320000290870667\n",
      "epoch:6 Train Loss:  0.6997833609580993, Accuracy 0.7240000367164612\n",
      "epoch:7 Train Loss:  0.7062665700912476, Accuracy 0.6839998960494995\n",
      "epoch:8 Train Loss:  0.7083525776863098, Accuracy 0.6559999585151672\n",
      "epoch:9 Train Loss:  0.6982383847236633, Accuracy 0.6959999799728394\n",
      "epoch:10 Train Loss:  0.4911837220191956, Accuracy 0.7720000147819519\n",
      "epoch:11 Train Loss:  0.5622819542884827, Accuracy 0.7440000176429749\n",
      "epoch:12 Train Loss:  0.45241996049880984, Accuracy 0.7760000228881836\n",
      "epoch:13 Train Loss:  0.4495764791965485, Accuracy 0.784000039100647\n",
      "epoch:14 Train Loss:  0.39772638082504275, Accuracy 0.8399999737739563\n",
      "epoch:15 Train Loss:  0.5083131432533264, Accuracy 0.7639999985694885\n",
      "epoch:16 Train Loss:  0.39984482526779175, Accuracy 0.8079999685287476\n",
      "epoch:17 Train Loss:  0.3658371865749359, Accuracy 0.8240000009536743\n",
      "epoch:18 Train Loss:  0.39194111824035643, Accuracy 0.8199999928474426\n",
      "epoch:19 Train Loss:  0.3996711492538452, Accuracy 0.8400000333786011\n",
      "epoch:20 Train Loss:  0.38845967650413515, Accuracy 0.8159999847412109\n",
      "epoch:21 Train Loss:  0.32788909375667574, Accuracy 0.85999995470047\n",
      "epoch:22 Train Loss:  0.2728866010904312, Accuracy 0.8920000195503235\n",
      "epoch:23 Train Loss:  0.20979287326335908, Accuracy 0.9079999923706055\n",
      "epoch:24 Train Loss:  0.26284932494163515, Accuracy 0.8799999952316284\n",
      "epoch:25 Train Loss:  0.29217693507671355, Accuracy 0.8920000195503235\n",
      "epoch:26 Train Loss:  0.26574093401432036, Accuracy 0.8920000195503235\n",
      "epoch:27 Train Loss:  0.2275524452328682, Accuracy 0.9199999570846558\n",
      "epoch:28 Train Loss:  0.22476139962673186, Accuracy 0.8999999761581421\n",
      "epoch:29 Train Loss:  0.17838053405284882, Accuracy 0.9160000085830688\n",
      "epoch:30 Train Loss:  0.1919768899679184, Accuracy 0.9279999732971191\n",
      "epoch:31 Train Loss:  0.17457049041986467, Accuracy 0.9239999651908875\n",
      "epoch:32 Train Loss:  0.19954121261835098, Accuracy 0.9239999651908875\n",
      "epoch:33 Train Loss:  0.16574801802635192, Accuracy 0.9239999651908875\n",
      "epoch:34 Train Loss:  0.14657780528068542, Accuracy 0.940000057220459\n",
      "epoch:35 Train Loss:  0.1309211403131485, Accuracy 0.972000002861023\n",
      "epoch:36 Train Loss:  0.14809245467185975, Accuracy 0.9399999380111694\n",
      "epoch:37 Train Loss:  0.17087912559509277, Accuracy 0.9319999814033508\n",
      "epoch:38 Train Loss:  0.14319371283054352, Accuracy 0.9479999542236328\n",
      "epoch:39 Train Loss:  0.1656600520014763, Accuracy 0.9199999570846558\n",
      "epoch:40 Train Loss:  0.10899710282683372, Accuracy 0.9559999704360962\n",
      "epoch:41 Train Loss:  0.11075209528207779, Accuracy 0.9639999270439148\n",
      "epoch:42 Train Loss:  0.10691985562443733, Accuracy 0.968000054359436\n",
      "epoch:43 Train Loss:  0.08947590440511703, Accuracy 0.968000054359436\n",
      "epoch:44 Train Loss:  0.1401142343878746, Accuracy 0.9520000219345093\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    train_loss_ep = []\n",
    "    train_acc_ep = []\n",
    "    \n",
    "    for train_batch in dod_df :\n",
    "        train_loss, train_acc = train_step(train_batch, True)\n",
    "        train_loss_ep.append(train_loss)\n",
    "        train_acc_ep.append(train_acc)\n",
    "    if i% 1 == 0:\n",
    "        print(f'epoch:{i} Train Loss:  {np.mean(train_loss_ep)}, Accuracy {np.mean(train_acc_ep)}')\n",
    "    train_loss_t.append(np.mean(train_loss_ep))\n",
    "    train_acc_t.append(np.mean(train_acc_ep))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"~/data/kaggle/dont-overfit/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = DofDataset(df_test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_ds, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 12s, sys: 51.6 s, total: 16min 4s\n",
      "Wall time: 15min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(test_dl):\n",
    "    logits = m(batch)\n",
    "    preds_np = np.argmax(logits.detach().numpy(), axis=1)\n",
    "    preds.extend(preds_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samp = pd.read_csv(\"~/data/kaggle/dont-overfit/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samp[\"target\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_samp.to_csv(\"~/data/kaggle/dont-overfit/subm-snn-fixed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 144k/144k [00:07<00:00, 18.8kB/s]\n",
      "Successfully submitted to Don't Overfit! II"
     ]
    }
   ],
   "source": [
    "! kaggle competitions submit -c dont-overfit-ii -f ~/data/kaggle/dont-overfit/subm-snn-fixed.csv -m \"fixed snn model, removed dropout from inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
